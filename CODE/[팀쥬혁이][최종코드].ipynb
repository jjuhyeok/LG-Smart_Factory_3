{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qe2o-O4u6OXn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import catboost\n",
    "from catboost import *\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mq9ums2L76Ph",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/drive/MyDrive/LG_Aimers_Phase_3/train.csv')\n",
    "test = pd.read_csv('/content/drive/MyDrive/LG_Aimers_Phase_3/test.csv')\n",
    "submit = pd.read_csv('/content/drive/MyDrive/LG_Aimers_Phase_3/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFv1EzkV-DlG",
    "outputId": "1e8fb1d8-c5bc-418f-e790-89f3c9d8f02b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525066667\n",
      "0.525085714\n",
      "0.534842857\n",
      "0.534950794\n"
     ]
    }
   ],
   "source": [
    "print(train[train['Y_Class'] == 0]['Y_Quality'].max())\n",
    "print(train[train['Y_Class'] == 1]['Y_Quality'].min())\n",
    "print(train[train['Y_Class'] == 1]['Y_Quality'].max())\n",
    "print(train[train['Y_Class'] == 2]['Y_Quality'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "87Q1AMDI_7S_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def del_columns(train, test):\n",
    "    col_list = train.columns\n",
    "    nan_list = []\n",
    "    nan_cnt = []\n",
    "    nan_col = []\n",
    "    full_list = []\n",
    "    for col in col_list:\n",
    "        if train[col].isnull().sum() == 0 :\n",
    "            full_list.append(col)\n",
    "            continue\n",
    "        nan_list.append([col, train[col].isnull().sum()])\n",
    "        nan_cnt.append(train[col].isnull().sum())\n",
    "        nan_col.append(col)\n",
    "\n",
    "    del_col = []\n",
    "    for col in nan_list:\n",
    "        if col[1] == len(train):\n",
    "            del_col.append(col[0])\n",
    "    train = train.drop(columns=del_col)\n",
    "    test = test.drop(columns=del_col)\n",
    "\n",
    "    del_col = []\n",
    "    col_list = train.describe().columns\n",
    "    for col in col_list :\n",
    "        if col == 'Y_Class':\n",
    "            continue\n",
    "        if col == 'Y_Quality':\n",
    "            continue\n",
    "        if col == 'LINE':\n",
    "            continue\n",
    "        if col == 'PRODUCT_CODE':\n",
    "            continue\n",
    "        if train[col].nunique()==1 :\n",
    "            del_col.append(col)\n",
    "    train = train.drop(columns=del_col)\n",
    "    test = test.drop(columns=del_col)\n",
    "    \n",
    "    return train,test\n",
    "\n",
    "def make_train_test_dataset(train,test):\n",
    "    \n",
    "    '''\n",
    "    트레인데이터, 학습데이터 셋 만들기\n",
    "    '''\n",
    "    \n",
    "    train_x = train.drop(columns=['PRODUCT_ID','PRODUCT_CODE','Y_Class','Y_Quality'])\n",
    "    test_x = test.drop(columns=['PRODUCT_ID','PRODUCT_CODE'])\n",
    "    train_y = train['Y_Quality']\n",
    "    train_w = train[['Y_Class']]\n",
    "    return train_x, test_x, train_y, train_w\n",
    "\n",
    "\n",
    "def fillna(train,test,value):\n",
    "    train = train.fillna(value)\n",
    "    test = test.fillna(value)\n",
    "    return train,test\n",
    "\n",
    "def labelencoder(train,test,col_list):\n",
    "    \n",
    "    qual_col = col_list\n",
    "    for i in qual_col:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(train[i])\n",
    "        train[i] = le.transform(train[i])\n",
    "\n",
    "        for label in np.unique(test[i]): \n",
    "            if label not in le.classes_: \n",
    "                le.classes_ = np.append(le.classes_, label)\n",
    "        test[i] = le.transform(test[i]) \n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SXezYT84A3ov",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train, test = del_columns(train,test)\n",
    "train, test = fillna(train,test,-999999)\n",
    "#train_x, test_x, train_y, train_w = make_train_test_dataset(train,test)\n",
    "#train_x, test_x = labelencoder(train_x,test_x,['LINE'])\n",
    "train['PRODUCT_CODE'] = train['PRODUCT_CODE'].astype('category')\n",
    "train['LINE'] = train['LINE'].astype('category')\n",
    "\n",
    "test['PRODUCT_CODE'] = test['PRODUCT_CODE'].astype('category')\n",
    "test['LINE'] = test['LINE'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7mxkx7EXPpSB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_r = pd.concat([submit,test['PRODUCT_CODE']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fnlk4FtqLTzs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_A = train[train['PRODUCT_CODE'] == 'A_31']\n",
    "train_T = train[train['PRODUCT_CODE'] == 'T_31']\n",
    "train_O = train[train['PRODUCT_CODE'] == 'O_31']\n",
    "\n",
    "test_A = test[test['PRODUCT_CODE'] == 'A_31']\n",
    "test_T = test[test['PRODUCT_CODE'] == 'T_31']\n",
    "test_O = test[test['PRODUCT_CODE'] == 'O_31']\n",
    "\n",
    "submit_A = submit_r[submit_r['PRODUCT_CODE'] == 'A_31']\n",
    "submit_T = submit_r[submit_r['PRODUCT_CODE'] == 'T_31']\n",
    "submit_O = submit_r[submit_r['PRODUCT_CODE'] == 'O_31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Z4J4c1hzLiZc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_A_1 = train_A[(train_A['X_230'] == -999999) & (train_A['X_231'] == -999999) & (train_A['X_232'] == -999999) & (train_A['X_233'] == -999999) & (train_A['X_234'] == -999999) & (train_A['X_235'] == -999999) & (train_A['X_236'] == -999999)]\n",
    "train_T_1 = train_T[(train_T['X_3000'] == -999999) & (train_T['X_3001'] == -999999) & (train_T['X_3002'] == -999999) & (train_T['X_3003'] == -999999) & (train_T['X_3004'] == -999999) & (train_T['X_3005'] == -999999) & (train_T['X_3006'] == -999999)]\n",
    "#train_O_1 = train_O[(train_O['X_93'] == -999999) & (train_O['X_94'] == -999999) & (train_O['X_95'] == -999999) & (train_O['X_96'] == -999999)]\n",
    "\n",
    "train_A_2 = train_A[(train_A['X_230'] != -999999) & (train_A['X_231'] != -999999) & (train_A['X_232'] != -999999) & (train_A['X_233'] != -999999) & (train_A['X_234'] != -999999) & (train_A['X_235'] != -999999) & (train_A['X_236'] != -999999)]\n",
    "train_T_2 = train_T[(train_T['X_3000'] != -999999) & (train_T['X_3001'] != -999999) & (train_T['X_3002'] != -999999) & (train_T['X_3003'] != -999999) & (train_T['X_3004'] != -999999) & (train_T['X_3005'] != -999999) & (train_T['X_3006'] != -999999)]\n",
    "#train_O_2 = train_O[(train_O['X_93'] != -999999) & (train_O['X_94'] != -999999) & (train_O['X_95'] != -999999) & (train_O['X_96'] != -999999)]\n",
    "\n",
    "test_A_1 = test_A[(test_A['X_230'] == -999999) & (test_A['X_231'] == -999999) & (test_A['X_232'] == -999999) & (test_A['X_233'] == -999999) & (test_A['X_234'] == -999999) & (test_A['X_235'] == -999999) & (test_A['X_236'] == -999999)]\n",
    "test_T_1 = test_T[(test_T['X_3000'] == -999999) & (test_T['X_3001'] == -999999) & (test_T['X_3002'] == -999999) & (test_T['X_3003'] == -999999) & (test_T['X_3004'] == -999999) & (test_T['X_3005'] == -999999) & (test_T['X_3006'] == -999999)]\n",
    "#test_O_1 = test_O[(test_O['X_93'] == -999999) & (test_O['X_94'] == -999999) & (test_O['X_95'] == -999999) & (test_O['X_96'] == -999999)]\n",
    "\n",
    "test_A_2 = test_A[(test_A['X_230'] != -999999) & (test_A['X_231'] != -999999) & (test_A['X_232'] != -999999) & (test_A['X_233'] != -999999) & (test_A['X_234'] != -999999) & (test_A['X_235'] != -999999) & (test_A['X_236'] != -999999)]\n",
    "test_T_2 = test_T[(test_T['X_3000'] != -999999) & (test_T['X_3001'] != -999999) & (test_T['X_3002'] != -999999) & (test_T['X_3003'] != -999999) & (test_T['X_3004'] != -999999) & (test_T['X_3005'] != -999999) & (test_T['X_3006'] != -999999)]\n",
    "#test_O_2 = test_O[(test_O['X_93'] != -999999) & (test_O['X_94'] != -999999) & (test_O['X_95'] != -999999) & (test_O['X_96'] != -999999)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "M3uphZWCS0np"
   },
   "outputs": [],
   "source": [
    "train_A_1_indices = train_A.index[(train_A['X_230'] == -999999) & (train_A['X_231'] == -999999) & (train_A['X_232'] == -999999) & (train_A['X_233'] == -999999) & (train_A['X_234'] == -999999) & (train_A['X_235'] == -999999) & (train_A['X_236'] == -999999)]\n",
    "train_T_1_indices = train_T.index[(train_T['X_3000'] == -999999) & (train_T['X_3001'] == -999999) & (train_T['X_3002'] == -999999) & (train_T['X_3003'] == -999999) & (train_T['X_3004'] == -999999) & (train_T['X_3005'] == -999999) & (train_T['X_3006'] == -999999)]\n",
    "#train_O_1_indices = train_O.index[(train_O['X_93'] == -999999) & (train_O['X_94'] == -999999) & (train_O['X_95'] == -999999) & (train_O['X_96'] == -999999)]\n",
    "\n",
    "train_A_1 = train_A.loc[train_A_1_indices]\n",
    "train_T_1 = train_T.loc[train_T_1_indices]\n",
    "#train_O_1 = train_O.loc[train_O_1_indices]\n",
    "\n",
    "train_A_2_indices = train_A.index[(train_A['X_230'] != -999999) | (train_A['X_231'] != -999999) | (train_A['X_232'] != -999999) | (train_A['X_233'] != -999999) | (train_A['X_234'] != -999999) | (train_A['X_235'] != -999999) | (train_A['X_236'] != -999999)]\n",
    "train_T_2_indices = train_T.index[(train_T['X_3000'] != -999999) | (train_T['X_3001'] != -999999) | (train_T['X_3002'] != -999999) | (train_T['X_3003'] != -999999) | (train_T['X_3004'] != -999999) | (train_T['X_3005'] != -999999) | (train_T['X_3006'] != -999999)]\n",
    "#train_O_2_indices = train_O.index[(train_O['X_93'] != -999999) | (train_O['X_94'] != -999999) | (train_O['X_95'] != -999999) | (train_O['X_96'] != -999999)]\n",
    "\n",
    "train_A_2 = train_A.loc[train_A_2_indices]\n",
    "train_T_2 = train_T.loc[train_T_2_indices]\n",
    "#train_O_2 = train_O.loc[train_O_2_indices]\n",
    "\n",
    "test_A_1_indices = test_A.index[(test_A['X_230'] == -999999) & (test_A['X_231'] == -999999) & (test_A['X_232'] == -999999) & (test_A['X_233'] == -999999) & (test_A['X_234'] == -999999) & (test_A['X_235'] == -999999) & (test_A['X_236'] == -999999)]\n",
    "test_T_1_indices = test_T.index[(test_T['X_3000'] == -999999) & (test_T['X_3001'] == -999999) & (test_T['X_3002'] == -999999) & (test_T['X_3003'] == -999999) & (test_T['X_3004'] == -999999) & (test_T['X_3005'] == -999999) & (test_T['X_3006'] == -999999)]\n",
    "#test_O_1_indices = test_O.index[(test_O['X_93'] == -999999) & (test_O['X_94'] == -999999) & (test_O['X_95'] == -999999) & (test_O['X_96'] == -999999)]\n",
    "\n",
    "test_A_1 = test_A.loc[test_A_1_indices]\n",
    "test_T_1 = test_T.loc[test_T_1_indices]\n",
    "#test_O_1 = test_O.loc[test_O_1_indices]\n",
    "\n",
    "test_A_2_indices = test_A.index[(test_A['X_230'] != -999999) | (test_A['X_231'] != -999999) | (test_A['X_232'] != -999999) | (test_A['X_233'] != -999999) | (test_A['X_234'] != -999999) | (test_A['X_235'] != -999999) | (test_A['X_236'] != -999999)]\n",
    "test_T_2_indices = test_T.index[(test_T['X_3000'] != -999999) | (test_T['X_3001'] != -999999) | (test_T['X_3002'] != -999999) | (test_T['X_3003'] != -999999) | (test_T['X_3004'] != -999999) | (test_T['X_3005'] != -999999) | (test_T['X_3006'] != -999999)]\n",
    "#test_O_2_indices = test_O.index[(test_O['X_93'] != -999999) | (test_O['X_94'] != -999999) | (test_O['X_95'] != -999999) | (test_O['X_96'] != -999999)]\n",
    "\n",
    "test_A_2 = test_A.loc[test_A_2_indices]\n",
    "test_T_2 = test_T.loc[test_T_2_indices]\n",
    "#test_O_2 = test_O.loc[test_O_2_indices]\n",
    "\n",
    "submit_A_1 = submit_A.loc[test_A_1_indices]\n",
    "submit_T_1 = submit_T.loc[test_T_1_indices]\n",
    "#submit_O_1 = submit_O.loc[test_O_1_indices]\n",
    "\n",
    "submit_A_2 = submit_A.loc[test_A_2_indices]\n",
    "submit_T_2 = submit_T.loc[test_T_2_indices]\n",
    "#submit_O_2 = submit_O.loc[test_O_2_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "m--S5xcaNagu"
   },
   "outputs": [],
   "source": [
    "train_A_1, test_A_1 = del_columns(train_A_1,test_A_1)\n",
    "train_T_1, test_T_1 = del_columns(train_T_1,test_T_1)\n",
    "#train_O_1, test_O_1 = del_columns(train_O_1,test_O_1)\n",
    "\n",
    "train_A_2, test_A_2 = del_columns(train_A_2,test_A_2)\n",
    "train_T_2, test_T_2 = del_columns(train_T_2,test_T_2)\n",
    "#train_O_2, test_O_2 = del_columns(train_O_2,test_O_2)\n",
    "\n",
    "train_O, test_O = del_columns(train_O,test_O)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vyViVrP2OY6S"
   },
   "outputs": [],
   "source": [
    "train_A_1_x, test_A_1_x, train_A_1_y, train_A_1_w = make_train_test_dataset(train_A_1,test_A_1)\n",
    "train_A_2_x, test_A_2_x, train_A_2_y, train_A_2_w = make_train_test_dataset(train_A_2,test_A_2)\n",
    "\n",
    "train_T_1_x, test_T_1_x, train_T_1_y, train_T_1_w  = make_train_test_dataset(train_T_1,test_T_1)\n",
    "train_T_2_x, test_T_2_x, train_T_2_y, train_T_2_w  = make_train_test_dataset(train_T_2,test_T_2)\n",
    "\n",
    "train_O_x, test_O_x, train_O_y, train_O_w = make_train_test_dataset(train_O,test_O)\n",
    "\n",
    "#train_O_1_x, test_O_1_x, train_O_1_y, train_O_1_w = make_train_test_dataset(train_O_1,test_O_1)\n",
    "#train_O_2_x, test_O_2_x, train_O_2_y, train_O_2_w = make_train_test_dataset(train_O_2,test_O_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "EjsYWc3NWlD3"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import copy\n",
    "from itertools import product\n",
    "\n",
    "def get_best_threshold_spliter(y_pred, y_true_cls, model=None, training=True):\n",
    "    if training:\n",
    "        #search_space = [[2, 4, 6, 18, 36], [1, 3, 5, 7, 9, 27, 54]]\n",
    "        search_space = [[2, 4, 6], [1, 3, 5, 7, 9]]\n",
    "        best_score = -np.inf\n",
    "        output_pred = []\n",
    "        model = None\n",
    "        for depth, min_samples in product(*search_space): \n",
    "            model = DecisionTreeClassifier(\n",
    "                criterion=\"gini\", max_features=1.0,\n",
    "                max_depth=depth, min_samples_leaf=min_samples, random_state=42\n",
    "            )\n",
    "\n",
    "            model.fit(y_pred, y_true_cls)\n",
    "            y_pred_cls = model.predict(y_pred)\n",
    "            score = metrics.f1_score(y_true_cls, y_pred_cls, average=\"macro\")\n",
    "            if ((best_score < score)):\n",
    "                best_score = score\n",
    "                print(f\"Best score : {best_score}\")\n",
    "                output_pred = y_pred_cls.copy()\n",
    "                model = copy.deepcopy(model)\n",
    "        return model, output_pred\n",
    "    else:\n",
    "        output_pred = model.predict(y_pred)\n",
    "        return output_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Om87u1lmXKWm"
   },
   "outputs": [],
   "source": [
    "A1_stats = pd.DataFrame({\"qual\": train_A_1_y, \"cls\": train_A_1_w[\"Y_Class\"]}).groupby(\"cls\")[\"qual\"].describe()\n",
    "A2_stats = pd.DataFrame({\"qual\": train_A_2_y, \"cls\": train_A_2_w[\"Y_Class\"]}).groupby(\"cls\")[\"qual\"].describe()\n",
    "\n",
    "T1_stats = pd.DataFrame({\"qual\": train_T_1_y, \"cls\": train_T_1_w[\"Y_Class\"]}).groupby(\"cls\")[\"qual\"].describe()\n",
    "T2_stats = pd.DataFrame({\"qual\": train_T_2_y, \"cls\": train_T_2_w[\"Y_Class\"]}).groupby(\"cls\")[\"qual\"].describe()\n",
    "\n",
    "O_stats = pd.DataFrame({\"qual\": train_O_y, \"cls\": train_O_w[\"Y_Class\"]}).groupby(\"cls\")[\"qual\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "EBNOudnSeO9q",
    "outputId": "c5c21b76-0684-4c79-dfc6-98c2f0376b6d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.530601</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.525916</td>\n",
       "      <td>0.529938</td>\n",
       "      <td>0.530954</td>\n",
       "      <td>0.532101</td>\n",
       "      <td>0.533702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.535078</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.534951</td>\n",
       "      <td>0.535014</td>\n",
       "      <td>0.535078</td>\n",
       "      <td>0.535141</td>\n",
       "      <td>0.535205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count      mean       std       min       25%       50%       75%  \\\n",
       "cls                                                                      \n",
       "1      6.0  0.530601  0.002681  0.525916  0.529938  0.530954  0.532101   \n",
       "2      2.0  0.535078  0.000180  0.534951  0.535014  0.535078  0.535141   \n",
       "\n",
       "          max  \n",
       "cls            \n",
       "1    0.533702  \n",
       "2    0.535205  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jSR_rq3uPN62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0091839\ttotal: 74.2ms\tremaining: 1m 14s\n",
      "500:\tlearn: 0.0000824\ttotal: 7.67s\tremaining: 7.64s\n",
      "999:\tlearn: 0.0000006\ttotal: 15.3s\tremaining: 0us\n",
      "Best score : 0.9910741366610338\n",
      "Best score : 1.0\n",
      "0:\tlearn: 0.0107289\ttotal: 55.1ms\tremaining: 55s\n",
      "500:\tlearn: 0.0001342\ttotal: 16.2s\tremaining: 16.1s\n",
      "999:\tlearn: 0.0000015\ttotal: 32.5s\tremaining: 0us\n",
      "Best score : 1.0\n",
      "0:\tlearn: 0.0045023\ttotal: 31.8ms\tremaining: 31.8s\n",
      "500:\tlearn: 0.0004268\ttotal: 8.02s\tremaining: 7.99s\n",
      "999:\tlearn: 0.0000479\ttotal: 16s\tremaining: 0us\n",
      "Best score : 0.989345738295318\n",
      "Best score : 1.0\n",
      "0:\tlearn: 0.0066603\ttotal: 22.6ms\tremaining: 22.6s\n",
      "500:\tlearn: 0.0009733\ttotal: 5.48s\tremaining: 5.46s\n",
      "999:\tlearn: 0.0002340\ttotal: 11s\tremaining: 0us\n",
      "Best score : 0.9848294622305921\n",
      "Best score : 1.0\n",
      "0:\tlearn: 0.0028491\ttotal: 6.53ms\tremaining: 6.53s\n",
      "500:\tlearn: 0.0000413\ttotal: 1.83s\tremaining: 1.82s\n",
      "999:\tlearn: 0.0000006\ttotal: 3.63s\tremaining: 0us\n",
      "Best score : 1.0\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "clf = catboost.CatBoostRegressor(\n",
    "    learning_rate=0.05,# 0.05\n",
    "    verbose=500,\n",
    "    iterations=1000, #1000\n",
    "    depth=6,\n",
    "    l2_leaf_reg=5, #5\n",
    "    border_count=254,cat_features=['LINE'],\n",
    "    random_seed=313)\n",
    "##################\n",
    "clf.fit(train_A_1_x, train_A_1_y)\n",
    "train_pred_A1 = clf.predict(train_A_1_x)\n",
    "pred_A1 = clf.predict(test_A_1_x)\n",
    "\n",
    "reg_prob = np.abs(np.stack([train_pred_A1 - A1_stats.loc[i, \"mean\"] \n",
    "                            for i in range(3) if i in A1_stats.index], axis=1))\n",
    "\n",
    "model_threshold, train_pred_A1 = get_best_threshold_spliter(reg_prob, train_A_1_w[\"Y_Class\"].values, training=True)\n",
    "\n",
    "reg_prob = np.abs(np.stack([pred_A1 - A1_stats.loc[i, \"mean\"] \n",
    "                            for i in range(3) if i in A1_stats.index], axis=1))\n",
    "\n",
    "pred_A1 = get_best_threshold_spliter(reg_prob, y_true_cls=None, model=model_threshold, training=False)\n",
    "##################\n",
    "\n",
    "##################\n",
    "clf.fit(train_A_2_x, train_A_2_y)\n",
    "train_pred_A2 = clf.predict(train_A_2_x)\n",
    "pred_A2 = clf.predict(test_A_2_x)\n",
    "reg_prob = np.abs(np.stack([train_pred_A2 - A2_stats.loc[i, \"mean\"] \n",
    "                            for i in range(3) if i in A2_stats.index], axis=1))\n",
    "model_threshold, train_pred_A2 = get_best_threshold_spliter(reg_prob, train_A_2_w[\"Y_Class\"].values, training=True)\n",
    "\n",
    "reg_prob = np.abs(np.stack([pred_A2 - A2_stats.loc[i, \"mean\"] \n",
    "                            for i in range(3) if i in A2_stats.index], axis=1))\n",
    "\n",
    "pred_A2 = get_best_threshold_spliter(reg_prob, y_true_cls=None, model=model_threshold, training=False)\n",
    "##################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################\n",
    "clf.fit(train_T_1_x, train_T_1_y)\n",
    "train_pred_T1 = clf.predict(train_T_1_x)\n",
    "pred_T1 = clf.predict(test_T_1_x)\n",
    "reg_prob = np.abs(np.stack([train_pred_T1 - T1_stats.loc[i, \"mean\"] \n",
    "                            for i in range(3) if i in T1_stats.index], axis=1))\n",
    "model_threshold, train_pred_T1 = get_best_threshold_spliter(reg_prob, train_T_1_w[\"Y_Class\"].values, training=True)\n",
    "\n",
    "reg_prob = np.abs(np.stack([pred_T1 - T1_stats.loc[i, \"mean\"] \n",
    "                            for i in range(3) if i in T1_stats.index], axis=1))\n",
    "pred_T1 = get_best_threshold_spliter(reg_prob, y_true_cls=None, model=model_threshold, training=False)\n",
    "##################\n",
    "\n",
    "\n",
    "\n",
    "##################\n",
    "clf.fit(train_T_2_x, train_T_2_y)\n",
    "train_pred_T2 = clf.predict(train_T_2_x)\n",
    "pred_T2 = clf.predict(test_T_2_x)\n",
    "reg_prob = np.abs(np.stack([train_pred_T2 - T2_stats.loc[i, \"mean\"] \n",
    "                            for i in range(3) if i in T2_stats.index], axis=1))\n",
    "model_threshold, train_pred_T2 = get_best_threshold_spliter(reg_prob, train_T_2_w[\"Y_Class\"].values, training=True)\n",
    "\n",
    "reg_prob = np.abs(np.stack([pred_T2 - T2_stats.loc[i, \"mean\"] \n",
    "                            for i in range(3) if i in T2_stats.index], axis=1))\n",
    "pred_T2 = get_best_threshold_spliter(reg_prob, y_true_cls=None, model=model_threshold, training=False)\n",
    "##################\n",
    "clf.fit(train_O_x, train_O_y)\n",
    "train_pred_O = clf.predict(train_O_x)\n",
    "pred_O = clf.predict(test_O_x)\n",
    "reg_prob = np.abs(np.stack([train_pred_O - O_stats.loc[i, \"mean\"] \n",
    "                            for i in range(3) if i in O_stats.index], axis=1))\n",
    "model_threshold, train_pred_O = get_best_threshold_spliter(reg_prob, train_O_w[\"Y_Class\"].values, training=True)\n",
    "\n",
    "reg_prob = np.abs(np.stack([pred_O - O_stats.loc[i, \"mean\"]\n",
    "                 for i in range(3) if i in O_stats.index], axis=1))\n",
    "pred_O = get_best_threshold_spliter(reg_prob, y_true_cls=None, model=model_threshold, training=False)\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "X54J4kp8enxa"
   },
   "outputs": [],
   "source": [
    "submit_A_1['Y_Class'] = pred_A1\n",
    "submit_A_2['Y_Class'] = pred_A2\n",
    "\n",
    "submit_T_1['Y_Class'] = pred_T1\n",
    "submit_T_2['Y_Class'] = pred_T2\n",
    "\n",
    "submit_O['Y_Class'] = pred_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8lWXg94euVI",
    "outputId": "4d9b61ea-ed77-449e-ddf8-c50458cc9772",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    414\n",
       "2     76\n",
       "0     45\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_combined = pd.concat([submit_A_1, submit_A_2, submit_T_1, submit_T_2, submit_O], axis=0)\n",
    "submit_combined = submit_combined.reset_index(drop=True)\n",
    "submit_combined = submit_combined.sort_values('PRODUCT_ID')\n",
    "submit_combined.drop(['PRODUCT_CODE'],axis=1,inplace=True)\n",
    "submit_combined = submit_combined.reset_index(drop=True)\n",
    "submit_combined.to_csv('upgrade1_dt.csv',index=False)\n",
    "submit_combined['Y_Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
